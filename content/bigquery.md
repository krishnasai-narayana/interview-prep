# Hadoop
+ [What are the main components of a Hadoop Application?](#What-are-the-main-components-of-a-Hadoop-Application)
+ [What is the core concept behind Apache Hadoop framework?](#What-is-the-core-concept-behind-Apache-Hadoop-framework)
+ [What is Hadoop Streaming?](#What-is-Hadoop-Streaming)
+ [What is BigQuery, and how does it fit into the data engineering ecosystem?](#What-is-BigQuery-and-how-does-it-fit-into-the-data-engineering-ecosystem)
+ [How does BigQuery handle data storage and processing?](#How-does-BigQuery-handle-data-storage-and-processing)
+ [What are the key advantages of using BigQuery?](#What-are-the-key-advantages-of-using-BigQuery)
+ [What is the difference between BigQuery and traditional relational databases?](#What-is-the-difference-between-BigQuery-and-traditional-relational-databases)
+ [What are the default port numbers on which  Nodes run in Hadoop?](#What-are-the-default-port-numbers-on-which-Nodes-run-in-Hadoop)
+ [How will you disable a Block Scanner on HDFS DataNode?](#How-will-you-disable-a-Block-Scanner-on-HDFS-DataNode)
+ [How will you get the distance between two nodes in Apache Hadoop?](#How-will-you-get-the-distance-between-two-nodes-in-Apache-Hadoop)
+ [Why do we use commodity hardware in Hadoop?](#Why-do-we-use-commodity-hardware-in-Hadoop)
+ [How does inter cluster data copying works in Hadoop?](#How-does-inter-cluster-data-copying-works-in-Hadoop)
+ [How can we update a file at an arbitrary location in HDFS?](#How-can-we-update-a-file-at-an-arbitrary-location-in-HDFS)
+ [What is Replication factor in HDFS?](#What-is-Replication-factor-in-HDFS)
+ [What is the difference between NAS and DAS in Hadoop cluster?](#What-is-the-difference-between-NAS-and-DAS-in-Hadoop-cluster)
+ [What are the two messages that NameNode receives from DataNode?](#What-are-the-two-messages-that-NameNode-receives-from-DataNode)
+ [How does indexing work in Hadoop?](#How-does-indexing-work-in-Hadoop)
+ [What data is stored in a HDFS NameNode?](#What-data-is-stored-in-a-HDFS-NameNode)
+ [What would happen if NameNode crashes in a HDFS cluster?](#What-would-happen-if-NameNode-crashes-in-a-HDFS-cluster)
+ [What are the main functions of Secondary NameNode?](#What-are-the-main-functions-of-Secondary-NameNode)
+ [What happens if HDFS file is set with replication factor of 1 and DataNode crashes?](#What-happens-if-HDFS-file-is-set-with-replication-factor-of-1-and-DataNode-crashes)
+ [What is the meaning of Rack Awareness in Hadoop?](#What-is-the-meaning-of-Rack-Awareness-in-Hadoop)
+ [How will you check if a file exists in HDFS?](#How-will-you-check-if-a-file-exists-in-HDFS)
+ [Why do we use fsck command in HDFS?](#Why-do-we-use-fsck-command-in-HDFS)
+ [What will happen when NameNode is down and a user submits a new job?](#What-will-happen-when-NameNode-is-down-and-a-user-submits-a-new-job)
+ [What are the core methods of a Reducer in Hadoop?](#What-are-the-core-methods-of-a-Reducer-in-Hadoop)
+ [What are the primary phases of a Reducer in Hadoop?](#What-are-the-primary-phases-of-a-Reducer-in-Hadoop)
+ [What is the use of Context object in Hadoop?](#What-is-the-use-of-Context-object-in-Hadoop)
+ [How does partitioning work in Hadoop?](#How-does-partitioning-work-in-Hadoop)
+ [What is a Combiner in Hadoop?](#What-is-a-Combiner-in-Hadoop)
+ [What is the default replication factor in HDFS?](#What-is-the-default-replication-factor-in-HDFS)
+ [How much storage is allocated by HDFS for storing a file of 25 MB size?](#How-much-storage-is-allocated-by-HDFS-for-storing-a-file-of-25-MB-size)
+ [Why does HDFS store data in Block structure?](#Why-does-HDFS-store-data-in-Block-structure)
+ [How will you create a custom Partitioner in a Hadoop job?](#How-will-you-create-a-custom-Partitioner-in-a-Hadoop-job)
+ [What is a Checkpoint node in HDFS?](#What-is-a-Checkpoint-node-in-HDFS)
+ [What is a Backup Node in HDFS?](#What-is-a-Backup-Node-in-HDFS)
+ [What is the meaning of term Data Locality in Hadoop?](#What-is-the-meaning-of-term-Data-Locality-in-Hadoop)
+ [What is a Balancer in HDFS?](#What-is-a-Balancer-in-HDFS)
+ [What are the important points a NameNode considers before selecting the DataNode for placing a data block?](#What-are-the-important-points-a-NameNode-considers-before-selecting-the-DataNode-for-placing-a-data-block)
+ [How will you replace HDFS data volume before shutting down a DataNode?](#How-will-you-replace-HDFS-data-volume-before-shutting-down-a-DataNode)
+ [What are the important configuration files in Hadoop?](#What-are-the-important-configuration-files-in-Hadoop)
+ [How will you monitor memory used in a Hadoop cluster?](#How-will-you-monitor-memory-used-in-a-Hadoop-cluster)
+ [Why do we need Serialization in Hadoop map reduce methods?](#Why-do-we-need-Serialization-in-Hadoop-map-reduce-methods)
+ [What is the use of Distributed Cache in Hadoop?](#What-is-the-use-of-Distributed-Cache-in-Hadoop)
+ [How will you synchronize the changes made to a file in Distributed Cache in Hadoop?](#How-will-you-synchronize-the-changes-made-to-a-file-in-Distributed-Cache-in-Hadoop)
+ [Can you elaborate about Mapreduce Job](#Can-you-elaborate-about-Mapreduce-job)
+ [Why compute nodes and the storage nodes are the same?](#Why-compute-nodes-and-the-storage-nodes-are-the-same)
+ [What is the configuration object importance in Mapreduce?](#What-is-the-configuration-object-importance-in-Mapreduce)
+ [Where Mapreduce not recommended?](#Where-Mapreduce-not-recommended?)
+ [What is Namenode and it’s responsibilities?](#What-is-Namenode-and-it’s-responsibilities)
+ [What is Jobtracker’s responsibility?](#What-is-Jobtracker’s-responsibility)
+ [What are the Jobtracker and Tasktracker?](#What-are-the-Jobtracker-and-Tasktracker)
+ [What is Job scheduling importance in Hadoop Mapreduce?](#What-is-Job-scheduling-importance-in-Hadoop-Mapreduce)
+ [When used Reducer?](#When-used-Reducer)
+ [Where the Shuffle and Sort process does?](#Where-the-Shuffle-and-Sort-process-does)
+ [Java is mandatory to write Mapreduce Jobs?](#Java-is-mandatory-to-write-Mapreduce-Jobs)
+ [What methods can controle the Map And Reduce function’s output?](#What-methods-can-controle-the-Map-And-Reduce-function’s-output)
+ [What is the main difference between Mapper And Reducer?](#What-is-the-main-difference-between-Mapper-And-Reducer)
+ [Why compute Nodes and the Storage Nodes are same?](#Why-compute-Nodes-and-the-Storage-Nodes-are-same?)
+ [What is difference between mapside join and reduce side join?](#What-is-difference-between-mapside-join-and-reduce-side-join)
+ [What happen if number of Reducer is 0?](#What-happen-if-number-of-Reducer-is-0)
+ [When we are goes to Combiner? Why it is Recommendable?](#When-we-are-goes-to-Combiner)
+ [What is the main difference between Mapreduce Combiner and Reducer?](#What-is-the-main-difference-between-Mapreduce-Combiner-and-Reducer)
+ [What Is Partition?](#What-is-partition)
+ [When we goes to Partition?](#When-we-goes-to-Partition)
+ [What are the important steps when you are partitioning table?](#What-are-the-important-steps-when-you-are-partitioning-table)
+ [Can you elaborate Mapreduce Job architecture?](#Can-you-elaborate-Mapreduce-Job-architecture)
+ [Why task Tracker launch child Jvm?](#Why-task-Tracker-launch-child-Jvm)
+ [Why JobClient and Job Tracker submits job resources to file system?](#Why-Jobclient-and-Job-Tracker-submits-job-resources-to-file-system)
+ [How many Mappers and Reducers can run?](#How-many-Mappers-and-Reducers-can-run)
+ [What is InputSplit?](#What-is-Inputsplit)
+ [How to configure the split value?](#How-to-configure-the-split-value)
+ [How much ram required to process 64mb data?](#How-much-ram-required-to-process-64mb-data)
+ [What is difference between block And split?](#What-is-difference-between-block-And-split)
+ [Why Hadoop Framework reads a file parallel why not sequential?](#Why-Hadoop-Framework-reads-a-file-parallel-why-not-sequential)
+ [If I am change block size from 64 to 128?](#If-I-am-change-block-size-from-64-to-128)
+ [What is IsSplitable()?](#What-is-Issplitable())
+ [How much Hadoop allows maximum block size and minimum block size?](#How-much-Hadoop-allows-maximum-block-size-and-minimum-block-size)
+ [What are the Job Resource files?](#What-are-the-Job-Resource-files)
+ [What’s the Mapreduce Job consists?](#What’s-the-Mapreduce-Job-consists)
+ [What is the data locality?](#What-is-the-data-locality)
+ [What is speculative execution?](#What-is-speculative-execution)
+ [What is chain Mapper?](#What-is-chain-Mapper)
+ [How to do value level comparison?](#How-to-do-value-level-comparison)
+ [What is setup and clean up methods?](#What-is-setup-and-clean-up-methods)
+ [How many slots allocate for each task?](#How-many-slots-allocate-for-each-task)
+ [Why TaskTracker launch child Jvm to do a task? Why not use Existent Jvm?](#Why-Tasktracker-launch-child-Jvm-to-do-a-task)
+ [What main configuration parameters are specified in Mapreduce?](#What-main-configuration-parameters-are-specified-in-Mapreduce)
+ [What is identity Mapper?](#What-is-identity-Mapper)
+ [What is RecordReader in a MapReduce?](#What-is-RecordReader-in-a-MapReduce)
+ [What is OutputCommitter?](#What-is-OutputCommitter)
+ [What are the parameters of Mappers and Reducers?](#What-are-the-parameters-of-Mappers-and-Reducers)
+ [Explain JobConf in Mapreduce?](#Explain-Jobconf-in-Mapreduce)
+ [Explain Job scheduling through Jobtracker?](#Explain-Job-scheduling-through-Jobtracker)
+ [What is SequenceFileInputFormat?](#What-is-SequenceFileInputFormat)
+ [Explain how input and output data format of the Hadoop Framework?](#Explain-how-input-and-output-data-format-of-the-Hadoop-Framework)
+ [What are the restriction to the Key and Value Class ?](#What-are-the-restriction-to-the-Key-and-Value-Class)
+ [Explain the wordcount implementation via Hadoop Framework?](#Explain-the-wordcount-implementation-via-Hadoop-Framework)
+ [How Mapper is instantiated in a running Job?](#How-Mapper-is-instantiated-in-a-running-Job)
+ [Which are the methods in the Mapper Interface?](#Which-are-the-methods-in-the-Mapper-Interface)
+ [What happens if You don't Override the Mapper methods and keep them as it is?](#What-happens-if-You-don't-Override-the-Mapper-methods-and-keep-them-as-it-is)
+ [What is the use of context Object?](#What-is-the-use-of-context-Object)
+ [How can you Add the arbitrary Key-value pairs in your Mapper?](#How-can-you-Add-the-arbitrary-Key-value-pairs-in-your-Mapper)
+ [How Does Mapper's Run() Method Works?](#How-does-Mapper's-run-method-works)
+ [Which Object can be used to get the progress of a particular Job?](#Which-Object-can-be-used-to-get-the-progress-of-a-particular-Job)
+ [What is next step after Mapper Or Maptask?](#What-is-next-step-after-Mapper-Or-Maptask)
+ [How can we control particular Key should go in a specific Reducer?](#How-can-we-control-particular-Key-should-go-in-a-specific-Reducer)
+ [What is the use of Combiner?](#What-is-the-use-of-Combiner)
+ [How many Maps are there in a particular Job?](#How-many-Maps-are-there-in-a-particular-Job)
+ [What is the Reducer used for?](#What-is-the-Reducer-used-for)
+ [Explain the core methods of the Reducer?](#Explain-the-core-methods-of-the-Reducer)
+ [What are the primary phases of the Reducer?](#What-are-the-primary-phases-of-the-Reducer)
+ [Explain the Shuffle?](#Explain-the-Shuffle)
+ [Explain the Reducer's sort phase?](#Explain-the-Reducer's-sort-phase)
+ [Explain the Reducer's reduce phase?](#Explain-the-Reducer's-reduce-phase)
+ [How many Reducers should be configured?](#How-many-Reducers-should-be-configured)
+ [It can be possible that a Job has 0 Reducers?](#It-can-be-possible-that-a-Job-has-0-Reducers)
+ [What happens if number of Reducers are 0?](#What-happens-if-number-of-Reducers-are-0)
+ [How many instances of Jobtracker can run on a Hadoop Cluster?](#How-many-instances-of-Jobtracker-can-run-on-a-Hadoop-Cluster)
+ [What is the Jobtracker and what it performs in a Hadoop Cluster?](#What-is-the-Jobtracker-and-what-it-performs-in-a-Hadoop-Cluster)
+ [How a task is scheduled by a Jobtracker?](#How-a-task-is-scheduled-by-a-Jobtracker)
+ [How many instances of Tasktracker run on a Hadoop Cluster?](#How-many-instances-of-Tasktracker-run-on-a-Hadoop-Cluster)
+ [How many maximum Jvm can run on a Slave Node?](#How-many-maximum-Jvm-can-run-on-a-Slave-Node)
+ [What is Nas?](#What-is-Nas)
+ [How Hdfs differs with Nfs?](#How-Hdfs-differs-with-Nfs)
+ [How does a NameNode handle the failure of the Data Nodes?](#How-does-a-NameNode-handle-the-failure-of-the-Data-Nodes)
+ [Can Reducer talk with each other?](#Can-Reducer-talk-with-each-other)
+ [Where the Mapper's intermediate data will be stored?](#Where-the-Mapper's-intermediate-data-will-be-stored)
+ [What is the Hadoop Mapreduce api contract for a Key and Value Class?](#What-is-the-Hadoop-Mapreduce-api-contract-for-a-Key-and-Value-Class)
+ [What is a IdentityMapper and IdentityReducer in Mapreduce?](#What-is-a-IdentityMapper-and-IdentityReducer-in-Mapreduce)
+ [What is the meaning of Speculative Execution in Hadoop?](#What-is-the-meaning-of-Speculative-Execution-in-Hadoop)
+ [How Hdfs is different from traditional File Systems?](#How-Hdfs-is-different-from-traditional-File-Systems)
+ [What is Hdfs block size and how is it different from Traditional File System block size?](#What-is-Hdfs-block-size-and-how-is-it-different-from-Traditional-File-System-block-size)
+ [What is a NameNode and how many instances of NameNode run on a Hadoop Cluster?](#What-is-a-NameNode-and-how-many-instances-of-NameNode-run-on-a-Hadoop-Cluster)
+ [How the client communicates with Hdfs?](#How-the-client-communicates-with-Hdfs)
+ [How the Hdfs blocks are replicated?](#How-the-Hdfs-blocks-are-replicated)
+ [Can you give some examples of Big Data?](#Can-you-give-some-examples-of-Big-Data)
+ [What is the basic difference between traditional Rdbms and Hadoop?](#What-is-the-basic-difference-between-traditional-Rdbms-and-Hadoop)
+ [What is structured and unstructured Data?](#What-is-structured-and-unstructured-Data)
+ [Since the data is replicated thrice in Hdfs so does it mean that any calculation done on One Node will also be replicated on the other Two?](#Since-the-data-is-replicated-thrice-in-Hdfs-so-does-it-mean-that-any-calculation-done-on-One-Node-will-also-be-replicated-on-the-other-Two)
+ [What is throughput and how does Hdfs get a good throughput?](#What-is-throughput-and-how-does-Hdfs-get-a-good-throughput)
+ [What is streaming access?](#What-is-streaming-access)
+ [What is a Commodity Hardware so does Commodity Hardware include Ram?](#What-is-a-Commodity-Hardware-so-does-Commodity-Hardware-include-Ram)
+ [Is NameNode also a Commodity?](#Is-NameNode-also-a-Commodity)
+ [What is a Metadata?](#What-is-a-Metadata?)
+ [What is a Daemon?](#What-is-a-Daemon)
+ [What is a Heartbeat in Hdfs?](#What-is-a-Heartbeat-in-Hdfs)
+ [How indexing is done in Hdfs?](#How-indexing-is-done-in-Hdfs)
+ [If a Data Node is full how it's identified?](#If-a-Data-Node-is-full-how-it's-identified)
+ [If DataNodes increase then do we need to upgrade NameNode?](#If-DataNodes-increase-then-do-we-need-to-upgrade-NameNode)
+ [Are Job Tracker and Task Trackers present in separate machines?](#Are-Job-Tracker-and-Task-Trackers-present-in-separate-machines)
+ [On what basis NameNode will decide which DataNode to write on?](#On-what-basis-NameNode-will-decide-which-DataNode-to-write-on)
+ [Who is a user in Hdfs?](#Who-is-a-user-in-Hdfs)
+ [Is client the end user in Hdfs?](#Is-client-the-end-user-in-Hdfs)
+ [What is the Communication Channel between client and NameNode/DataNode?](#What-is-the-Communication-Channel-between-client-and-NameNode/DataNode)
+ [What is a Rack?](#What-is-a-Rack)
+ [On what basis Data will be stored on a Rack?](#On-what-basis-Data-will-be-stored-on-a-Rack)
+ [Do we need to place 2nd and 3rd Data in Rack 2 only?](#Do-we-need-to-place-2nd-and-3rd-Data-in-Rack-2-only)
+ [What if Rack 2 and DataNode fails?](#What-if-Rack-2-and-DataNode-fails)
+ [What is the difference between Gen1 and Gen2 Hadoop with regards to the NameNode?](#What-is-the-difference-between-Gen1-and-Gen2-Hadoop-with-regards-to-the-NameNode)
+ [Do we require two servers for the NameNode and the DataNodes?](#Do-we-require-two-servers-for-the-NameNode-and-the-DataNodes)
+ [Why are the number of splits equal to the number of Maps?](#Why-are-the-number-of-splits-equal-to-the-number-of-Maps)
+ [Is a Job split into maps?](#Is-a-Job-split-into-maps)
+ [Which are the two types of writes in Hdfs?](#Which-are-the-two-types-of-writes-In-Hdfs)
+ [Why reading is done in parallel and writing is not in Hdfs?](#Why-reading-is-done-in-parallel-and-writing-is-not-in-Hdfs)
+ [Can Hadoop be compared to Nosql Database like Cassandra?](#Can-Hadoop-be-compared-to-Nosql-Database-like-Cassandra)
+ [How JobTracker schedules a task?](#How-JobTracker-schedules-a-task)
+ [What is a Task Tracker in Hadoop and how many instances of Task Tracker run on a Hadoop Cluster?](#What-is-a-Task-Tracker-in-Hadoop-and-how-many-instances-of-Task-Tracker-run-on-a-Hadoop-Cluster)
+ [What is a task instance in Hadoop and where does it run?](#What-is-a-task-instance-in-Hadoop-and-where-does-it-run)
+ [What is configuration of a typical Slave Node on Hadoop Cluster and how many Jvms run on a Slave Node?](#What-is-configuration-of-a-typical-Slave-Node-on-Hadoop-Cluster-and-how-many-Jvms-run-on-a-Slave-Node)
+ [How NameNode handles DataNode failures?](#How-NameNode-handles-DataNode-failures)
+ [Does Mapreduce programming model provide a way for Reducers to communicate with each other and in a Mapreduce Job can a Reducer communicate with another Reducer?](#Does-Mapreduce-programming-model-provide-a-way-for-Reducers-to-communicate-with-each-other-and-in-a-Mapreduce-Job-can-a-Reducer-communicate-with-another-Reducer)
+ [Can I set the number of Reducers to Zero?](#Can-I-set-the-number-of-Reducers-to-Zero)
+ [Where is the Mapper Output intermediate Kay-value data stored?](#Where-is-the-Mapper-Output-intermediate-Kay-value-data-stored)
+ [If Reducers do not start before all Mappers finish then why does the progress on Mapreduce Job shows something like Map 50 percents Reduce 10 percents and why Reducers progress percentage is displayed when Mapper is not Finished yet?](#If-Reducers-do-not-start-before-all-Mappers-finish-then-why-does-the-progress-on-Mapreduce-Job-shows-something-like-Map-50-percents-Reduce-10-percents-and-why-Reducers-progress-percentage-is-displayed-when-Mapper-is-not-Finished-yet)
+ [Explain in brief the three Modes in which Hadoop can be run?](#Explain-in-brief-the-three-Modes-in-which-Hadoop-can-be-run)
+ [Explain what are the features of Standalone local Mode?](#Explain-what-are-the-features-of-Standalone-local-Mode)
+ [What are the features of fully distributed mode?](#What-are-the-features-of-fully-distributed-mode)
+ [Explain what are the main features Of pseudo mode?](#Explain-what-are-the-main-features-Of-pseudo-mode)
+ [What are the port numbers of NameNode and JobTracker and TaskTracker?](#What-are-the-port-numbers-of-NameNode-and-JobTracker-and-TaskTracker)
+ [Tell us what is a spill factor with respect to the ram?](#Tell-us-what-is-a-spill-factor-with-respect-to-the-ram)
+ [Is fs.mapr working for a single directory?](#Is-fs.mapr-working-for-a-single-directory)
+ [Which are the three main Hdfs-site.xml properties?](#Which-are-the-three-main-Hdfs-site.xml-properties)
+ [How can I restart NameNode?](#How-can-I-restart-Namenode)
+ [How can we check whether Namenode is working or not?](#How-can-we-check-whether-Namenode-is-working-or-not)
+ [At times you get a connection refused Java Exception when you run the file system check command Hadoop fsck?](#At-times-you-get-a-connection-refused-Java-Exception-when-you-run-the-file-system-check-command-Hadoop-fsck)
+ [What is the use of the command Mapred.job.tracker?](#What-is-the-use-of-the-command-Mapred.job.tracker)
+ [What does etc/init.d do?](#What-does-etc.init.d-do)
+ [How can we look for the Namenode in the browser?](#How-can-we-look-for-the-Namenode-in-the-browser)
+ [What do masters and slaves consist of?](#What-do-masters-and-slaves-consist-of)
+ [What is the function Of Hadoop-env.sh and where is it present?](#What-is-the-function-Of-Hadoop-env.sh-and-where-is-it-present)
+ [Can we have multiple entries in the master files?](#Can-we-have-multiple-entries-in-the-master-files)
+ [In Hadoop_pid_dir and what does pid stands for?](#In-Hadoop_pid_dir-and-what-does-pid-stands-for)
+ [What does Hadoop-metrics and properties file do?](#What-does-Hadoop-metrics-and-properties-file-do)
+ [What are the network requirements for hadoop?](#What-are-the-network-requirements-for-hadoop)
+ [Why do we need a password-less ssh in fully distributed environment?](#Why-do-we-need-a-passwordless-ssh-in-fully-distributed-environment)
+ [What will happen if a NameNode has no data?](#What-will-happen-if-a-NameNode-has-no-data)
+ [What happens to job tracker when NameNode is down?](#What-happens-to-job-tracker-when-NameNode-is-down)
+ [Explain what do you mean by formatting of the Dfs?](#Explain-what-do-you-mean-by-formatting-of-the-Dfs)
+ [We use Unix variants for hadoop and can we use Microsoft Windows for the same?](#We-use-Unix-variants-for-hadoop-and-can-we-use-Microsoft-Windows-for-the-same)
+ [Which one decides the input split hdfs client or NameNode?](#Which-one-decides-the-input-split-hdfs-client-or-NameNode)
+ [Can you tell me if we can create a hadoop cluster from scratch?](#Can-you-tell-me-if-we-can-create-a-hadoop-cluster-from-scratch)
+ [Explain the significance of ssh and what is the port on which port does ssh work and why do we need password in ssh local host?](#Explain-the-significance-of-ssh-and-what-is-the-port-on-which-port-does-ssh-work-and-why-do-we-need-password-in-ssh-local-host)
+ [What is ssh and explain in detail about ssh communication between masters and the slaves?](#What-is-ssh-and-explain-in-detail-about-ssh-communication-between-masters-and-the-slaves)
+ [Can You Tell Is What Will Happen To A NameNode and When Job Tracker Is Not Up And Running?](#Can-you-tell-is-what-will-happen-to-a-NameNode-and-when-Job-tracker-is-not-up-and-running)


## What are the main components of a Hadoop Application?
Over the time, there are various forms in which a Hadoop application is defined. But in most of the cases there are following four core components of Hadoop application:
+ HDFS: This is the file system in which Hadoop data is stored. It is a distributed file system with very high bandwidth.
+ Hadoop Common_: This is common set of libraries and utilities used by Hadoop. 
+ Hadoop MapReduce: This is based on MapReduce algorithm for providing large-scale data processing.
+ Hadoop YARN: This is used for resource management in a Hadoop cluster. It can also schedule tasks for users.

[Table of Contents](#HADOOP)
 
## How does BigQuery handle data storage and processing?
BigQuery uses a distributed architecture for data storage and processing. It separates storage and compute, allowing users to scale each independently. Data is stored in Capacitor, a proprietary storage system, while processing is handled by Dremel, a distributed query execution engine.

[Table of Contents](#HADOOP)

## What are the key advantages of using BigQuery?
Some advantages of BigQuery include:
+ Scalability: It can handle massive datasets and query volumes.
+ Cost-effectiveness: Users only pay for the queries and storage they use.
+ Serverless architecture: No infrastructure management is required.
+ Integration with other GCP services: BigQuery can easily integrate with other GCP tools for data ingestion and processing.

[Table of Contents](#HADOOP)

## What is the difference between BigQuery and traditional relational databases?
BigQuery is a cloud-based, columnar data warehouse, whereas traditional relational databases are usually on-premises and row-based. BigQuery offers near-infinite scalability, while traditional databases have limitations based on hardware and storage capacity.

[Table of Contents](#HADOOP)
